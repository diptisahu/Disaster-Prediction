{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f5f0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf8a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text  target\n",
       "id                                                                            \n",
       "1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\" Function to clean the text \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    \n",
    "    # Remove numbers from string\n",
    "    texter = re.sub(pattern=r\"[+-]?\\d+(?:\\.\\d+)?\", repl=\"\", string=texter, count=0, flags=0)\n",
    "    texter = texter.replace(\"  \", \" \")\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    texter = re.sub(r'[^\\w\\s]', '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e81e9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './glove.6B.300d.txt'\n",
    "input_dim = 300\n",
    "\n",
    "vocab = {}\n",
    "with open(glove_dir, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        vocab[word] = vector\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' %len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d0c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "zero_padding = [0]*input_dim\n",
    "\n",
    "def get_embeddings(text, emb=\"LSTM\"):\n",
    "    if emb == \"DNN\":\n",
    "        embedding = [0]*input_dim\n",
    "        i = 0\n",
    "        for word in text.split(' '):\n",
    "            if word in vocab:\n",
    "                i += 1\n",
    "                embedding += vocab[word]\n",
    "\n",
    "        if i != 0:\n",
    "            embedding /= i\n",
    "\n",
    "#         scale = 0 # noise weight_scale\n",
    "#         noise = np.random.randn(input_dim)*scale\n",
    "#         embedding += noise\n",
    "    elif emb == \"LSTM\":\n",
    "        embedding = []\n",
    "        i = 0\n",
    "        for word in text.split(' '):\n",
    "            if i == max_len:\n",
    "                break\n",
    "            if word in vocab:\n",
    "                i += 1\n",
    "                embedding.append(vocab[word])\n",
    "        \n",
    "        while i < max_len:\n",
    "            i += 1\n",
    "            embedding.append(zero_padding)\n",
    "            \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf2017b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, emb=\"LSTM\"):\n",
    "    embeddings = []\n",
    "    for item in X:\n",
    "        item = clean(item)\n",
    "        embedding = get_embeddings(item, emb)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0778c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create embeddings for input\n",
    "cleaned_X = np.array(transform(df['text'], \"DNN\"))\n",
    "y = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence BERT\n",
    "\n",
    "# sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# sentence_embeddings = sbert_model.encode(cleaned_x, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8ae792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.0001\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47364287",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_tr = torch.tensor(X_train, dtype=torch.float)\n",
    "y_tr = torch.tensor(y_train)\n",
    "train = TensorDataset(X_tr, y_tr)\n",
    "trainloader = DataLoader(train, batch_size=batch_size)\n",
    "\n",
    "X_te = torch.tensor(X_test, dtype=torch.float)\n",
    "y_te = torch.tensor(y_test)\n",
    "test = TensorDataset(X_te, y_te)\n",
    "testloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3866d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(300, 500)\n",
    "        self.hidden1 = nn.Linear(500, 500)\n",
    "        self.hidden2 = nn.Linear(500, 500)\n",
    "        self.fc2 = nn.Linear(500, 20)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f665606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd39372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "net.train()\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        training_loss.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 500 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(trainloader), loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1800194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 80.74%\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "net.eval()\n",
    "outputs = net(X_te)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "total = y_te.size(0)\n",
    "correct = (predicted == y_te).sum()\n",
    "\n",
    "print(f'Accuracy of the model is: {100*correct/total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55f3caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29f1acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_X_test = np.array(transform(df_test['text'], \"DNN\"))\n",
    "X_test = torch.tensor(cleaned_X_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e43ac1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "net.eval()\n",
    "outputs_test = net(X_test)\n",
    "\n",
    "_, predicted_test = torch.max(outputs_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fd65e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3263])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9626dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'id': np.array(df_test['id']),\n",
    "       'target': np.array(predicted_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42787914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(data)\n",
    "df_submission.to_csv('submission.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f45e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
