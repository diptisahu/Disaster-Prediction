{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae7c43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb463465",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./embeddings/CBoW.pkl', 'rb')\n",
    "cbow = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f545af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./embeddings/skipgram.pkl', 'rb')\n",
    "skipgram = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa32469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./embeddings/fasttext.pkl', 'rb')\n",
    "fasttext = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0618478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id keyword location  \\\n",
       "0           0   1     NaN      NaN   \n",
       "1           1   4     NaN      NaN   \n",
       "2           2   5     NaN      NaN   \n",
       "3           3   6     NaN      NaN   \n",
       "4           4   7     NaN      NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0       deeds reason earthquake may allah forgive us       1  \n",
       "1              forest fire near la ronge sask canada       1  \n",
       "2  residents asked shelter place notified officer...       1  \n",
       "3  people receive wildfires evacuation orders cal...       1  \n",
       "4  got sent photo ruby alaska smoke wildfires pou...       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./embeddings/train_embed_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "127bc53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_padding = [0]*10\n",
    "\n",
    "def get_embeddings(text, emb):\n",
    "    embedding = [0]*10\n",
    "    i = 0\n",
    "    for word in text.split(' '):\n",
    "        if emb == \"cbow\":\n",
    "            if word in cbow:\n",
    "                i += 1\n",
    "                embedding += cbow[word]\n",
    "        \n",
    "        elif emb == \"skipgram\":\n",
    "            if word in skipgram:\n",
    "                i += 1\n",
    "                embedding += skipgram[word]\n",
    "                \n",
    "        elif emb == \"fasttext\":\n",
    "            if word in fasttext:\n",
    "                i += 1\n",
    "                embedding += fasttext[word]\n",
    "    if i != 0:\n",
    "        embedding /= i\n",
    "           \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7f0988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, emb):\n",
    "    embeddings = []\n",
    "    for item in X:\n",
    "        embedding = get_embeddings(item, emb)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b73f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_X = np.array(transform(df['text'], 'fasttext'))\n",
    "y = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f696b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.00001\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de490c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_tr = torch.tensor(X_train, dtype=torch.float)\n",
    "y_tr = torch.tensor(y_train)\n",
    "train = TensorDataset(X_tr, y_tr)\n",
    "trainloader = DataLoader(train, batch_size=batch_size)\n",
    "\n",
    "X_te = torch.tensor(X_test, dtype=torch.float)\n",
    "y_te = torch.tensor(y_test)\n",
    "test = TensorDataset(X_te, y_te)\n",
    "testloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86acaf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 500)\n",
    "        self.hidden1 = nn.Linear(500, 500)\n",
    "        self.hidden2 = nn.Linear(500, 500)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ccea041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65024423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6679\n",
      "Accuracy of the model is: 63.92%\n",
      "Epoch [2/10], Loss: 0.6787\n",
      "Accuracy of the model is: 66.73%\n",
      "Epoch [3/10], Loss: 0.6805\n",
      "Accuracy of the model is: 67.60%\n",
      "Epoch [4/10], Loss: 0.6763\n",
      "Accuracy of the model is: 66.90%\n",
      "Epoch [5/10], Loss: 0.6646\n",
      "Accuracy of the model is: 66.99%\n",
      "Epoch [6/10], Loss: 0.6348\n",
      "Accuracy of the model is: 66.73%\n",
      "Epoch [7/10], Loss: 0.7598\n",
      "Accuracy of the model is: 66.64%\n",
      "Epoch [8/10], Loss: 0.6547\n",
      "Accuracy of the model is: 66.99%\n",
      "Epoch [9/10], Loss: 0.6936\n",
      "Accuracy of the model is: 66.81%\n",
      "Epoch [10/10], Loss: 0.6603\n",
      "Accuracy of the model is: 66.90%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "net.train()\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        training_loss.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, loss.data))\n",
    "        \n",
    "    # Validation\n",
    "    net.eval()\n",
    "    outputs = net(X_te)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total = y_te.size(0)\n",
    "    correct = (predicted == y_te).sum()\n",
    "\n",
    "    print(f'Accuracy of the model is: {100*correct/total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce7a5bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af4ea947",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_X_test = np.array(transform(df_test['text'], 'fasttext'))\n",
    "X_test = torch.tensor(cleaned_X_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68434069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "net.eval()\n",
    "outputs_test = net(X_test)\n",
    "\n",
    "_, predicted_test = torch.max(outputs_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7125af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'id': np.array(df_test['id']),\n",
    "       'target': np.array(predicted_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "936db808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(data)\n",
    "df_submission.to_csv('submission_fasttext.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722088a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0c06959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"learn_rate\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[21:21:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/data/data.cc:592: Check failed: labels_.Size() == num_row_ (1142 vs. 3263) : Size of labels must equal to number of rows.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21312/3198577936.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#                             use_label_encoder=False,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                             seed=42)\n\u001b[1;32m---> 11\u001b[1;33m clf_xgb.fit(X_train,\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         )\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dataset name should not contain `-`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# into datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;31m# split up `test-error:0.1234`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m   1742\u001b[0m         \u001b[0mevnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1744\u001b[1;33m         _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1745\u001b[0m                                               \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \"\"\"\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [21:21:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/data/data.cc:592: Check failed: labels_.Size() == num_row_ (1142 vs. 3263) : Size of labels must equal to number of rows."
     ]
    }
   ],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            gamma=0.25,\n",
    "                            learn_rate=0.00001,\n",
    "                            max_depth=5,\n",
    "                            reg_lambda=0.25,\n",
    "                            scale_pos_weight=1,\n",
    "                            subsample=0.9,\n",
    "                            n_estimators=30,\n",
    "#                             use_label_encoder=False,\n",
    "                            seed=42)\n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            early_stopping_rounds=5,\n",
    "            eval_metric='error',     # used error as well\n",
    "            eval_set=[(X_test, y_test)])\n",
    "\n",
    "bst = clf_xgb.get_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a782b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
