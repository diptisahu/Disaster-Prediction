{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "797101f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3142d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text  target\n",
       "id                                                                            \n",
       "1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e771a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\" Function to clean the text \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    \n",
    "    # Remove numbers from string\n",
    "    texter = re.sub(pattern=r\"[+-]?\\d+(?:\\.\\d+)?\", repl=\"\", string=texter, count=0, flags=0)\n",
    "    texter = texter.replace(\"  \", \" \")\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    texter = re.sub(r'[^\\w\\s]', '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ea7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './glove.6B.300d.txt'\n",
    "input_dim = 300\n",
    "\n",
    "vocab = {}\n",
    "with open(glove_dir, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        vocab[word] = vector\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' %len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e55db23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "zero_padding = [0]*input_dim\n",
    "\n",
    "def get_embeddings(text, emb=\"LSTM\"):\n",
    "    if emb == \"DNN\":\n",
    "        embedding = [0]*input_dim\n",
    "        i = 0\n",
    "        for word in text.split(' '):\n",
    "            if word in vocab:\n",
    "                i += 1\n",
    "                embedding += vocab[word]\n",
    "\n",
    "        if i != 0:\n",
    "            embedding /= i\n",
    "\n",
    "#         scale = 0 # noise weight_scale\n",
    "#         noise = np.random.randn(input_dim)*scale\n",
    "#         embedding += noise\n",
    "    elif emb == \"LSTM\":\n",
    "        embedding = []\n",
    "        i = 0\n",
    "        for word in text.split(' '):\n",
    "            if i == max_len:\n",
    "                break\n",
    "            if word in vocab:\n",
    "                i += 1\n",
    "                embedding.append(vocab[word])\n",
    "        \n",
    "        while i < max_len:\n",
    "            i += 1\n",
    "            embedding.append(zero_padding)\n",
    "            \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bd7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, emb=\"LSTM\"):\n",
    "    embeddings = []\n",
    "    for item in X:\n",
    "        item = clean(item)\n",
    "        embedding = get_embeddings(item, emb)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7574c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create embeddings for input\n",
    "cleaned_X = np.array(transform(df['text'], \"DNN\"))\n",
    "y = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence BERT\n",
    "\n",
    "# sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# sentence_embeddings = sbert_model.encode(cleaned_x, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918d6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.0001\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bfe06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_tr = torch.tensor(X_train, dtype=torch.float)\n",
    "y_tr = torch.tensor(y_train)\n",
    "train = TensorDataset(X_tr, y_tr)\n",
    "trainloader = DataLoader(train, batch_size=batch_size)\n",
    "\n",
    "X_te = torch.tensor(X_test, dtype=torch.float)\n",
    "y_te = torch.tensor(y_test)\n",
    "test = TensorDataset(X_te, y_te)\n",
    "testloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8836d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(300, 500)\n",
    "        self.hidden1 = nn.Linear(500, 500)\n",
    "        self.hidden2 = nn.Linear(500, 500)\n",
    "        self.fc2 = nn.Linear(500, 20)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
