{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5f0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf8a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\" Function to clean the text \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    \n",
    "    # Remove numbers from string\n",
    "    texter = re.sub(pattern=r\"[+-]?\\d+(?:\\.\\d+)?\", repl=\"\", string=texter, count=0, flags=0)\n",
    "    texter = texter.replace(\"  \", \" \")\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    texter = re.sub(r'[^\\w\\s]', '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e81e9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './embeddings/glove.6B.300d.txt'\n",
    "input_dim = 300\n",
    "\n",
    "vocab = {}\n",
    "with open(glove_dir, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        vocab[word] = vector\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' %len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43d0c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "zero_padding = [0]*input_dim\n",
    "\n",
    "def get_embeddings(text, emb=\"LSTM\"):\n",
    "    if emb == \"DNN\":\n",
    "        embedding = [0]*input_dim\n",
    "        i = 0\n",
    "        for word in text.split(' '):\n",
    "            if word in vocab:\n",
    "                i += 1\n",
    "                embedding += vocab[word]\n",
    "\n",
    "        if i != 0:\n",
    "            embedding /= i\n",
    "\n",
    "        scale = 0.3 # noise weight_scale\n",
    "        noise = np.random.randn(input_dim)*scale\n",
    "        embedding += noise\n",
    "    elif emb == \"LSTM\":\n",
    "        embedding = []\n",
    "        i = 0\n",
    "        for word in text.split(' '):\n",
    "            if i == max_len:\n",
    "                break\n",
    "            if word in vocab:\n",
    "                i += 1\n",
    "                embedding.append(vocab[word])\n",
    "        \n",
    "        while i < max_len:\n",
    "            i += 1\n",
    "            embedding.append(zero_padding)\n",
    "            \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf2017b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, emb=\"LSTM\"):\n",
    "    embeddings = []\n",
    "    for item in X:\n",
    "        item = clean(item)\n",
    "        embedding = get_embeddings(item, emb)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0778c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create embeddings for input\n",
    "cleaned_X = np.array(transform(df['text'], \"DNN\"))\n",
    "# cleaned_X = np.array(transform(df['text']))\n",
    "y = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97ae3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence BERT\n",
    "\n",
    "# sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# sentence_embeddings = sbert_model.encode(cleaned_x, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd8ae792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 0.00001\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47364287",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_tr = torch.tensor(X_train, dtype=torch.float)\n",
    "y_tr = torch.tensor(y_train)\n",
    "train = TensorDataset(X_tr, y_tr)\n",
    "trainloader = DataLoader(train, batch_size=batch_size)\n",
    "\n",
    "X_te = torch.tensor(X_test, dtype=torch.float)\n",
    "y_te = torch.tensor(y_test)\n",
    "test = TensorDataset(X_te, y_te)\n",
    "testloader = DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3866d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(300, 500)\n",
    "        self.hidden1 = nn.Linear(500, 500)\n",
    "        self.hidden2 = nn.Linear(500, 500)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(500)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f665606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd39372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.7227\n",
      "Accuracy of the model is: 55.52%\n",
      "Epoch [2/15], Loss: 0.7320\n",
      "Accuracy of the model is: 59.81%\n",
      "Epoch [3/15], Loss: 0.7859\n",
      "Accuracy of the model is: 61.38%\n",
      "Epoch [4/15], Loss: 0.8178\n",
      "Accuracy of the model is: 64.01%\n",
      "Epoch [5/15], Loss: 0.7211\n",
      "Accuracy of the model is: 65.59%\n",
      "Epoch [6/15], Loss: 0.8369\n",
      "Accuracy of the model is: 66.02%\n",
      "Epoch [7/15], Loss: 0.7481\n",
      "Accuracy of the model is: 67.43%\n",
      "Epoch [8/15], Loss: 0.7344\n",
      "Accuracy of the model is: 67.95%\n",
      "Epoch [9/15], Loss: 0.8260\n",
      "Accuracy of the model is: 68.21%\n",
      "Epoch [10/15], Loss: 0.7284\n",
      "Accuracy of the model is: 68.65%\n",
      "Epoch [11/15], Loss: 0.7649\n",
      "Accuracy of the model is: 68.65%\n",
      "Epoch [12/15], Loss: 0.6236\n",
      "Accuracy of the model is: 68.65%\n",
      "Epoch [13/15], Loss: 0.6260\n",
      "Accuracy of the model is: 69.53%\n",
      "Epoch [14/15], Loss: 0.7033\n",
      "Accuracy of the model is: 69.26%\n",
      "Epoch [15/15], Loss: 0.6308\n",
      "Accuracy of the model is: 69.61%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "net.train()\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        training_loss.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, loss.data))\n",
    "        \n",
    "    # Validation\n",
    "    net.eval()\n",
    "    outputs = net(X_te)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total = y_te.size(0)\n",
    "    correct = (predicted == y_te).sum()\n",
    "\n",
    "    print(f'Accuracy of the model is: {100*correct/total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac04c141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.720510095642933"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predicted, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "55f3caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "29f1acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_X_test = np.array(transform(df_test['text'], \"DNN\"))\n",
    "X_test = torch.tensor(cleaned_X_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e43ac1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "net.eval()\n",
    "outputs_test = net(X_test)\n",
    "\n",
    "_, predicted_test = torch.max(outputs_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5fd65e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3263])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a9626dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'id': np.array(df_test['id']),\n",
    "       'target': np.array(predicted_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "42787914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(data)\n",
    "df_submission.to_csv('submission_lstm.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c23a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
